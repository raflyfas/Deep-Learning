{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRv59qPNsgUS"
      },
      "outputs": [],
      "source": [
        "pip install transformers[torch] datasets evaluate rouge_score tqdm wandb accelerate openpyxl sentencepiece protobuf ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import numpy as np\n",
        "\n",
        "# 1. Konfigurasi\n",
        "MODEL_CHECKPOINT = \"t5-base\"  # Model pre-trained\n",
        "MAX_INPUT_LENGTH = 512        # Panjang maksimal input (konteks + pertanyaan)\n",
        "MAX_TARGET_LENGTH = 32        # Panjang maksimal output (jawaban)\n",
        "\n",
        "# 2. Load Dataset SQuAD\n",
        "# SQuAD berisi kolom: 'id', 'title', 'context', 'question', 'answers'\n",
        "raw_datasets = load_dataset(\"squad\")\n",
        "print(\"Contoh data:\", raw_datasets[\"train\"][0])\n",
        "\n",
        "# 3. Load Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "print(\"Berhasil import dan load dataset!\")"
      ],
      "metadata": {
        "id": "i1AQL7lztIrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    # Loop melalui setiap data\n",
        "    for i in range(len(examples[\"context\"])):\n",
        "        # Format input khusus T5\n",
        "        input_text = f\"question: {examples['question'][i]} context: {examples['context'][i]}\"\n",
        "        inputs.append(input_text)\n",
        "\n",
        "        # Ambil teks jawaban pertama (SQuAD bisa punya beberapa referensi jawaban, ambil yang pertama untuk training)\n",
        "        targets.append(examples[\"answers\"][i][\"text\"][0])\n",
        "\n",
        "    # Tokenisasi Input\n",
        "    model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Tokenisasi Target (Jawaban)\n",
        "    labels = tokenizer(targets, max_length=MAX_TARGET_LENGTH, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Ganti padding token di label menjadi -100 agar tidak dihitung dalam loss\n",
        "    labels[\"input_ids\"] = [\n",
        "        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
        "    ]\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Terapkan preprocessing ke seluruh dataset (Train & Validation)\n",
        "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True, remove_columns=raw_datasets[\"train\"].column_names)"
      ],
      "metadata": {
        "id": "iJX7MYVXtE6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load Model T5\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "# 2. Setup Argumen Training\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./t5-finetuned-squad\",\n",
        "    # evaluation_strategy=\"epoch\",      # Evaluasi setiap akhir epoch (removed due to error)\n",
        "    # save_strategy=\"epoch\",          # Simpan model setiap akhir epoch (removed due to error)\n",
        "    learning_rate=2e-5,               # Learning rate standar untuk fine-tuning\n",
        "    per_device_train_batch_size=8,   # Sesuaikan dengan memori GPU (bisa diturunkan ke 8 atau 4)\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,               # Hanya simpan 3 checkpoint terakhir\n",
        "    num_train_epochs=2,               # Jumlah putaran latihan\n",
        "    predict_with_generate=True,       # Penting: Generate teks saat evaluasi untuk hitung metrik\n",
        "    fp16=True,                        # Gunakan Mixed Precision (lebih cepat di GPU modern)\n",
        "    push_to_hub=False,\n",
        "    # load_best_model_at_end=True,      # Muat model terbaik di akhir training (removed due to error)\n",
        ")\n",
        "\n",
        "# 3. Data Collator (Mengurus batching secara dinamis)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# 4. Inisialisasi Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "XrQWfM5_tJ3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "rvGPNMudtLwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk prediksi manual\n",
        "def ask_question(question, context):\n",
        "    # 1. Format input\n",
        "    input_text = f\"question: {question} context: {context}\"\n",
        "\n",
        "    # 2. Tokenisasi\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\") # Pastikan ke GPU jika pakai GPU\n",
        "\n",
        "    # 3. Generate Jawaban\n",
        "    outputs = model.generate(inputs, max_length=32)\n",
        "\n",
        "    # 4. Decode hasil token menjadi teks\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "# --- CONTOH PENGGUNAAN ---\n",
        "my_context = \"\"\"\n",
        "Monas atau Monumen Nasional adalah ikon kota Jakarta yang terletak di pusat kota.\n",
        "Tugu ini dibangun untuk mengenang perlawanan dan perjuangan rakyat Indonesia untuk merebut kemerdekaan\n",
        "dari pemerintahan kolonial Hindia Belanda. Pembangunan dimulai pada tanggal 17 Agustus 1961.\n",
        "\"\"\"\n",
        "\n",
        "my_question = \"Kapan pembangunan Monas dimulai?\"\n",
        "\n",
        "print(\"Konteks:\", my_context)\n",
        "print(\"Pertanyaan:\", my_question)\n",
        "print(\"-\" * 30)\n",
        "print(\"Jawaban Model:\", ask_question(my_question, my_context))"
      ],
      "metadata": {
        "id": "CCoUxh-TtMVB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}